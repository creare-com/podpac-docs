# Requirements

* Quick and simple to define arbitrary data source given podpac Coordinates and some kind of data
* Provide a base class for all other data types, including user defined data types

# Example Use cases

* I want to load tabular data from a local file and create a podpac data source quickly
* I want to create a data source class that provides access to a new server that serves GeoTIFF data
* I want to create a data source class the provides access to a new flat file data source
* I want to access my data on Backblaze B2 instead of S3 bucket
* I want to access a GeoServer which implements WCS
* I want to provide access to a new NASA dataset that is stored on S3 in a new data format

# Specification

## DataSource Class

`DataSource(Node)` is the base class from which all data other data sources are implemented. Extends the `Node` base class.

#### Traits

(See [Node documentation](https://creare-com.github.io/podpac-docs/user/api/podpac.core.node.html#podpac.core.node.Node) for nodes attributes)

- `source`: Any, required
    + The location of the source. Depending on the child node this can be a filepath, numpy array, or dictionary as a few examples.
- `interpolation`: `Interpolate()`  class (tbd)
    - Should include `interpolation_param` for all dims or single dims.  i.e. Enum('nearest', 'nearest_preview', 'bilinear', 'cubic', 'cubic_spline', 'lanczos', 'average', 'mode', 'gauss', 'max', 'min', 'med', 'q1', 'q3'), Default: `nearest`
- `coordinate_index_type`: Enum('list','numpy','xarray','pandas'). By default this is `numpy`
- `nan_vals`: List
    + list of values from source data that should be interpreted as 'no data' or 'nans' (replaces `no_data_vals`)

#### Properties

#### Contructor

- FUTURE: After implementing a govener on the request size, implement:
    + Take one input (i.e. `evaluate`) that will automatically execute the datasource at the native_coordinates on contruction. This will allow a shortcut when you just want to load a simple data source for processing with other more complication data sources

#### Methods

- `eval(coordinates, params=None, output=None, method=None)`: Evaluate this node using the supplied coordinates
    + `self.requested_coordinates` gets set to the coordinates that are input
    + remove dims that don't exist in native coordinates
    + `_determine_source_coordinates()` translates the `self.requested_coordinates` into `self.requested_source_coordinates`, `self.requested_source_coordinates_index` to get requested via `get_data`.
    + run `get_data`
    + Check/fix order of dims when UnitsDataArray or Xarray is returned from get_data. Otherwise create UnitsDataArray using values from get_data and requested_source_coordinates
    + Run `_interpolate()`
    + Output the user the UnitsDataArray passed back from interpolate
- `get_data(coordinates=self.requested_source_coordinates, coordinates_index=requested_source_coordinates_index)`:
    + Raise a `NotImplementedError`
    + `coordinates` and `coordinates_index` are guarenteed to exists in the datasource as calculated by `_determine_source_coordinates`
    + return an UnitsDataArray numpy array or xarray of values. this will get turned into a UnitsDataArray aftwards using `self.requested_source_coordinates` even if the xarray passes back coordinates
        * Need to check/fix order of dims in UnitsDataArray and Xarray case
- `get_native_coordinates()`: return the native coordinates from the data source. By default, this should return `self.native_coordinates` if defined, otherwise raise a `NotImplementedError`
- `definition()`: Pipeline node definition for DataSource nodes.
    + Transport mechanism for going to the cloud
    + Leave as is

#### Private Methods

- `_determine_source_coordinates()`: Use `self.requested_coordinates`, `self.native_coordinates`, `self.interpolate` to determine the requested coordinates translated into the source coordinates.
    + sets `self.requested_source_coordinates` (Coordinates) to the coordinates that need to get requested from the data source via `get_data`. These coordinates MUST exists exactly in the data source native coordinates. They coordinates that get returned may be affected by the type of interpolate() class used in request.
    + Based on `coordinate_index_type`, set `self.requested_source_coordinates_index` (Array[int], Array[boolean], List[slices])
    + Returns a UnitsDataArray for the data subset
- `_interpolate()`: Use `self.interpolate` and call the appropriate functions in the `interpolate` module
    + Returns a UnitDataArray which becomes the output of the eval method

#### Operators

## User Interface

Simple datasource that doesn't need its own subclass

```python
class ArraySource(DataSource):
    source = tl.Instance(np.ndarray)

    def get_data(self, coordinates, coordinates_index):
        return self.source[coordinates_index]
```

Using this basic class

```python
source = np.random.rand(101, 101)
source_coordinates = coordinates(lat=(-25, 25, 101), lon=(-25, 25, 101), order=['lat', 'lon'])
node = ArraySource(source=source, native_coordinates=source_coordinates)
output = node.eval(node.native_coordinates)
```

FUTURE: automatically execute

```python
source = np.random.rand(101, 101)
source_coordinates = coordinates(lat=(-25, 25, 101), lon=(-25, 25, 101), order=['lat', 'lon'])
node = ArraySource(source=source, native_coordinates=source_coordinates)
output = node.eval()
```

More Complicated Source. 
This datasource gets new `native_coordinates` every time the source updates.

```python
class RasterioSource(DataSource):
    
    source = tl.Unicode(allow_none=False)  # specifies source MUST be a Unicode
    dataset = tl.Any(allow_none=True)
    band = tl.CInt(1).tag(attr=True)
    
    @tl.default('dataset')
    def open_dataset(self, source):
        return module.open(source)

    @tl.observe('source')
    def _update_dataset(self):
        self.dataset = self.open_dataset()
        self.native_coordinates = self.get_native_coordinates()
        
    def get_native_coordinates(self):
        dlon = self.dataset.width
        dlat = self.dataset.height
        left, bottom, right, top = self.dataset.bounds

        return podpac.Coordinate(lat=(top, bottom, dlat),
                                 lon=(left, right, dlon),
                                 order=['lat', 'lon'])

    def get_data(self, coordinates, coordinates_index):
        data = self.dataset.read(coordinates_index)
        return data
```

## Developer interface


TODO: Add developer interface specs
